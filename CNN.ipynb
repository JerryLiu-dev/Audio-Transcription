{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb7119f6-dcb1-4e5b-bf1e-f6160623b628",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import *\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25bca30d-6f3c-435d-9ff6-7717feda649c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\tojer/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/jeribaldi/uncategorized/runs/2byjzjux\" target=\"_blank\">proud-bush-1</a></strong> to <a href=\"https://wandb.ai/jeribaldi/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors of label - 'bed': 100%|████████████████████████████████████████████| 1713/1713 [00:09<00:00, 180.70it/s]\n",
      "Saving vectors of label - 'cat': 100%|████████████████████████████████████████████| 1733/1733 [00:10<00:00, 170.34it/s]\n",
      "Saving vectors of label - 'happy': 100%|██████████████████████████████████████████| 1742/1742 [00:09<00:00, 185.25it/s]\n"
     ]
    }
   ],
   "source": [
    "wandb.init()\n",
    "config = wandb.config\n",
    "\n",
    "config.max_len = 11\n",
    "config.buckets = 20\n",
    "\n",
    "# Save data to array file first\n",
    "save_data_to_array(max_len=config.max_len, n_mfcc=config.buckets)\n",
    "\n",
    "labels=[\"bed\", \"happy\", \"cat\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66f6010-5227-4c7a-81d5-d11b7a0b6f88",
   "metadata": {},
   "source": [
    "# 1D and 2D Convolution on Audio Wave Spectrogram Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e0742b2-045f-45a8-90c5-8b8e74fb5acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loading train set and test set\n",
    "X_train, X_test, y_train, y_test = get_train_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "177ba672-3270-40d4-81e0-27368dc58e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Feature dimension\n",
    "channels = 1\n",
    "config.epochs = 50\n",
    "config.batch_size = 100\n",
    "\n",
    "num_classes = 3\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], config.buckets, config.max_len, channels)\n",
    "X_test = X_test.reshape(X_test.shape[0], config.buckets, config.max_len, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d6c3b32-9723-4b87-97cb-b118db433834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[100, :, :, 0])\n",
    "print(y_train[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ca2964d-67e2-4795-a9dc-0a510a069cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "200fe05d-86de-43d7-a5d2-fdb251101283",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], config.buckets, config.max_len)\n",
    "X_test = X_test.reshape(X_test.shape[0], config.buckets, config.max_len)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(config.buckets, config.max_len)))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "                  optimizer=\"adam\",\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21391e06-4cac-4cd4-971a-808aed3df9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2byjzjux) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 9372... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">proud-bush-1</strong>: <a href=\"https://wandb.ai/jeribaldi/uncategorized/runs/2byjzjux\" target=\"_blank\">https://wandb.ai/jeribaldi/uncategorized/runs/2byjzjux</a><br/>\n",
       "Find logs at: <code>.\\wandb\\run-20220114_222335-2byjzjux\\logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2byjzjux). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/jeribaldi/uncategorized/runs/2dfaxds0\" target=\"_blank\">fallen-microwave-2</a></strong> to <a href=\"https://wandb.ai/jeribaldi/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 1/98 [..............................] - ETA: 52s - loss: 49.7499 - accuracy: 0.3438WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0015s). Check your callbacks.\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 32.4137 - accuracy: 0.4232 - val_loss: 17.6696 - val_accuracy: 0.5381\n",
      "Epoch 2/50\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 10.9563 - accuracy: 0.6215 - val_loss: 8.5809 - val_accuracy: 0.6628\n",
      "Epoch 3/50\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 6.5338 - accuracy: 0.6922 - val_loss: 6.6589 - val_accuracy: 0.6932\n",
      "Epoch 4/50\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 5.1465 - accuracy: 0.7262 - val_loss: 5.2698 - val_accuracy: 0.7259\n",
      "Epoch 5/50\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 4.1745 - accuracy: 0.7506 - val_loss: 4.4622 - val_accuracy: 0.7336\n",
      "Epoch 6/50\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 3.6572 - accuracy: 0.7571 - val_loss: 4.2982 - val_accuracy: 0.7389\n",
      "Epoch 7/50\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 3.3014 - accuracy: 0.7667 - val_loss: 3.9561 - val_accuracy: 0.7365\n",
      "Epoch 8/50\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 3.0479 - accuracy: 0.7706 - val_loss: 3.8510 - val_accuracy: 0.7187\n",
      "Epoch 9/50\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 2.7028 - accuracy: 0.7799 - val_loss: 3.4376 - val_accuracy: 0.7327\n",
      "Epoch 10/50\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 2.6007 - accuracy: 0.7747 - val_loss: 3.6278 - val_accuracy: 0.7312\n",
      "Epoch 11/50\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 2.5596 - accuracy: 0.7735 - val_loss: 2.9988 - val_accuracy: 0.7452\n",
      "Epoch 12/50\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 2.2152 - accuracy: 0.7825 - val_loss: 2.7432 - val_accuracy: 0.7471\n",
      "Epoch 13/50\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 2.1585 - accuracy: 0.7831 - val_loss: 2.6498 - val_accuracy: 0.7433\n",
      "Epoch 14/50\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 1.9235 - accuracy: 0.7889 - val_loss: 2.5838 - val_accuracy: 0.7534\n",
      "Epoch 15/50\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 1.8237 - accuracy: 0.7808 - val_loss: 2.3688 - val_accuracy: 0.7567\n",
      "Epoch 16/50\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 1.8050 - accuracy: 0.7815 - val_loss: 2.4058 - val_accuracy: 0.7466\n",
      "Epoch 17/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 1.6869 - accuracy: 0.7860 - val_loss: 2.3842 - val_accuracy: 0.7288\n",
      "Epoch 18/50\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 1.5178 - accuracy: 0.7908 - val_loss: 2.2117 - val_accuracy: 0.7274\n",
      "Epoch 19/50\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 1.5155 - accuracy: 0.7831 - val_loss: 2.1014 - val_accuracy: 0.7408\n",
      "Epoch 20/50\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 1.3973 - accuracy: 0.7892 - val_loss: 2.0849 - val_accuracy: 0.7303\n",
      "Epoch 21/50\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 1.3320 - accuracy: 0.7863 - val_loss: 2.0040 - val_accuracy: 0.7423\n",
      "Epoch 22/50\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 1.3355 - accuracy: 0.7876 - val_loss: 1.8429 - val_accuracy: 0.7490\n",
      "Epoch 23/50\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 1.2457 - accuracy: 0.7892 - val_loss: 2.2980 - val_accuracy: 0.7144\n",
      "Epoch 24/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 1.1919 - accuracy: 0.7918 - val_loss: 1.9278 - val_accuracy: 0.7317\n",
      "Epoch 25/50\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 1.2572 - accuracy: 0.7934 - val_loss: 1.7267 - val_accuracy: 0.7486\n",
      "Epoch 26/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 1.1363 - accuracy: 0.8027 - val_loss: 1.6628 - val_accuracy: 0.7355\n",
      "Epoch 27/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 1.0512 - accuracy: 0.8014 - val_loss: 1.8349 - val_accuracy: 0.7139\n",
      "Epoch 28/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 1.2214 - accuracy: 0.7805 - val_loss: 1.6454 - val_accuracy: 0.7351\n",
      "Epoch 29/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 1.0436 - accuracy: 0.7972 - val_loss: 1.6798 - val_accuracy: 0.7288\n",
      "Epoch 30/50\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 1.0053 - accuracy: 0.7918 - val_loss: 1.6634 - val_accuracy: 0.7370\n",
      "Epoch 31/50\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 1.0113 - accuracy: 0.7937 - val_loss: 1.5660 - val_accuracy: 0.7461\n",
      "Epoch 32/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.9793 - accuracy: 0.7886 - val_loss: 1.3418 - val_accuracy: 0.7625\n",
      "Epoch 33/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.9378 - accuracy: 0.8021 - val_loss: 1.3611 - val_accuracy: 0.7543\n",
      "Epoch 34/50\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 0.9649 - accuracy: 0.7905 - val_loss: 1.4314 - val_accuracy: 0.7510\n",
      "Epoch 35/50\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.9278 - accuracy: 0.7947 - val_loss: 1.3131 - val_accuracy: 0.7471\n",
      "Epoch 36/50\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 0.9308 - accuracy: 0.7950 - val_loss: 1.3565 - val_accuracy: 0.7620\n",
      "Epoch 37/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.9124 - accuracy: 0.7924 - val_loss: 2.0222 - val_accuracy: 0.6773\n",
      "Epoch 38/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.8965 - accuracy: 0.7940 - val_loss: 1.3517 - val_accuracy: 0.7413\n",
      "Epoch 39/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.8387 - accuracy: 0.8011 - val_loss: 1.2942 - val_accuracy: 0.7428\n",
      "Epoch 40/50\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.8733 - accuracy: 0.7992 - val_loss: 1.2113 - val_accuracy: 0.7558\n",
      "Epoch 41/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.9162 - accuracy: 0.8017 - val_loss: 1.1841 - val_accuracy: 0.7577\n",
      "Epoch 42/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.9413 - accuracy: 0.7956 - val_loss: 1.1593 - val_accuracy: 0.7548\n",
      "Epoch 43/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.7767 - accuracy: 0.8059 - val_loss: 1.1880 - val_accuracy: 0.7514\n",
      "Epoch 44/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.7832 - accuracy: 0.8066 - val_loss: 1.1875 - val_accuracy: 0.7471\n",
      "Epoch 45/50\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 0.7928 - accuracy: 0.8043 - val_loss: 1.3483 - val_accuracy: 0.7336\n",
      "Epoch 46/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.8085 - accuracy: 0.8033 - val_loss: 1.4613 - val_accuracy: 0.7052\n",
      "Epoch 47/50\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.8086 - accuracy: 0.7966 - val_loss: 1.1783 - val_accuracy: 0.7548\n",
      "Epoch 48/50\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.8971 - accuracy: 0.7953 - val_loss: 1.2817 - val_accuracy: 0.7481\n",
      "Epoch 49/50\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.7644 - accuracy: 0.8062 - val_loss: 1.4589 - val_accuracy: 0.7182\n",
      "Epoch 50/50\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.7633 - accuracy: 0.8059 - val_loss: 1.0774 - val_accuracy: 0.7558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b4fa0eed90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init()\n",
    "model.fit(X_train, y_train_hot, epochs=config.epochs, validation_data=(X_test, y_test_hot), callbacks=[WandbCallback(data_type=\"image\", labels=labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c129bdc9-c3fd-41c6-972e-0c7f9312d1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3),\n",
    "                input_shape = (config.buckets,config.max_len, channels), activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(32, (3,3),\n",
    "                input_shape = (config.buckets,config.max_len, channels), activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30fe8c6f-514f-4d72-87ba-bd86c7207596",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68417ef1-178f-4889-964b-55021d9ff473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2dfaxds0) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 19796... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.42MB of 0.42MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▅▆▇▇▇▇█▇███████████████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▆▇▇▇▇▇▇█▇██▇▇▇▇█▆▇▇▆▇▇▇████▅▇▇████▆███</td></tr><tr><td>val_loss</td><td>█▄▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.80591</td></tr><tr><td>best_epoch</td><td>49</td></tr><tr><td>best_val_loss</td><td>1.07735</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>loss</td><td>0.76333</td></tr><tr><td>val_accuracy</td><td>0.75578</td></tr><tr><td>val_loss</td><td>1.07735</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1801 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">fallen-microwave-2</strong>: <a href=\"https://wandb.ai/jeribaldi/uncategorized/runs/2dfaxds0\" target=\"_blank\">https://wandb.ai/jeribaldi/uncategorized/runs/2dfaxds0</a><br/>\n",
       "Find logs at: <code>.\\wandb\\run-20220114_222646-2dfaxds0\\logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2dfaxds0). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/jeribaldi/uncategorized/runs/376817ud\" target=\"_blank\">genial-snowflake-3</a></strong> to <a href=\"https://wandb.ai/jeribaldi/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 1/98 [..............................] - ETA: 1:08 - loss: 1.9172 - accuracy: 0.1875WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0036s vs `on_train_batch_end` time: 0.0045s). Check your callbacks.\n",
      "98/98 [==============================] - 3s 20ms/step - loss: 0.8537 - accuracy: 0.6690 - val_loss: 0.4634 - val_accuracy: 0.8237\n",
      "Epoch 2/50\n",
      "98/98 [==============================] - 1s 12ms/step - loss: 0.3748 - accuracy: 0.8503 - val_loss: 0.3272 - val_accuracy: 0.8829\n",
      "Epoch 3/50\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 0.2792 - accuracy: 0.8959 - val_loss: 0.3736 - val_accuracy: 0.8584\n",
      "Epoch 4/50\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 0.2300 - accuracy: 0.9132 - val_loss: 0.3465 - val_accuracy: 0.8829\n",
      "Epoch 5/50\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 0.1591 - accuracy: 0.9441 - val_loss: 0.2630 - val_accuracy: 0.9133\n",
      "Epoch 6/50\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 0.1522 - accuracy: 0.9418 - val_loss: 0.2571 - val_accuracy: 0.9133\n",
      "Epoch 7/50\n",
      "98/98 [==============================] - 1s 11ms/step - loss: 0.0951 - accuracy: 0.9669 - val_loss: 0.5355 - val_accuracy: 0.8415\n",
      "Epoch 8/50\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 0.1076 - accuracy: 0.9582 - val_loss: 0.2431 - val_accuracy: 0.9253\n",
      "Epoch 9/50\n",
      "98/98 [==============================] - 1s 11ms/step - loss: 0.0732 - accuracy: 0.9762 - val_loss: 0.2309 - val_accuracy: 0.9316\n",
      "Epoch 10/50\n",
      "98/98 [==============================] - 1s 11ms/step - loss: 0.0549 - accuracy: 0.9843 - val_loss: 0.2932 - val_accuracy: 0.9157\n",
      "Epoch 11/50\n",
      "98/98 [==============================] - 1s 11ms/step - loss: 0.0819 - accuracy: 0.9701 - val_loss: 0.2316 - val_accuracy: 0.9268\n",
      "Epoch 12/50\n",
      "98/98 [==============================] - 1s 11ms/step - loss: 0.0383 - accuracy: 0.9878 - val_loss: 0.2552 - val_accuracy: 0.9321\n",
      "Epoch 13/50\n",
      "98/98 [==============================] - 1s 11ms/step - loss: 0.0566 - accuracy: 0.9788 - val_loss: 0.2604 - val_accuracy: 0.9292\n",
      "Epoch 14/50\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 0.0370 - accuracy: 0.9884 - val_loss: 0.2765 - val_accuracy: 0.9306\n",
      "Epoch 15/50\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 0.0246 - accuracy: 0.9926 - val_loss: 0.2813 - val_accuracy: 0.9355\n",
      "Epoch 16/50\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 0.0211 - accuracy: 0.9949 - val_loss: 0.2845 - val_accuracy: 0.9330\n",
      "Epoch 17/50\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 0.0105 - accuracy: 0.9994 - val_loss: 0.2889 - val_accuracy: 0.9321\n",
      "Epoch 18/50\n",
      "98/98 [==============================] - 1s 11ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2888 - val_accuracy: 0.9359\n",
      "Epoch 19/50\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2817 - val_accuracy: 0.9359\n",
      "Epoch 20/50\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3059 - val_accuracy: 0.9355\n",
      "Epoch 21/50\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2931 - val_accuracy: 0.9374\n",
      "Epoch 22/50\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3039 - val_accuracy: 0.9383\n",
      "Epoch 23/50\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3077 - val_accuracy: 0.9388\n",
      "Epoch 24/50\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3075 - val_accuracy: 0.9369\n",
      "Epoch 25/50\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 9.9479e-04 - accuracy: 1.0000 - val_loss: 0.3137 - val_accuracy: 0.9379\n",
      "Epoch 26/50\n",
      "98/98 [==============================] - 1s 11ms/step - loss: 9.3420e-04 - accuracy: 1.0000 - val_loss: 0.3147 - val_accuracy: 0.9369\n",
      "Epoch 27/50\n",
      "98/98 [==============================] - 1s 12ms/step - loss: 7.4063e-04 - accuracy: 1.0000 - val_loss: 0.3247 - val_accuracy: 0.9374\n",
      "Epoch 28/50\n",
      "98/98 [==============================] - 1s 12ms/step - loss: 6.9941e-04 - accuracy: 1.0000 - val_loss: 0.3219 - val_accuracy: 0.9379\n",
      "Epoch 29/50\n",
      "98/98 [==============================] - 1s 11ms/step - loss: 6.3700e-04 - accuracy: 1.0000 - val_loss: 0.3252 - val_accuracy: 0.9369\n",
      "Epoch 30/50\n",
      "98/98 [==============================] - 1s 13ms/step - loss: 5.6923e-04 - accuracy: 1.0000 - val_loss: 0.3292 - val_accuracy: 0.9379\n",
      "Epoch 31/50\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 5.0560e-04 - accuracy: 1.0000 - val_loss: 0.3353 - val_accuracy: 0.9374\n",
      "Epoch 32/50\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 5.0977e-04 - accuracy: 1.0000 - val_loss: 0.3396 - val_accuracy: 0.9364\n",
      "Epoch 33/50\n",
      "98/98 [==============================] - 1s 11ms/step - loss: 4.3799e-04 - accuracy: 1.0000 - val_loss: 0.3475 - val_accuracy: 0.9359\n",
      "Epoch 34/50\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 3.9075e-04 - accuracy: 1.0000 - val_loss: 0.3528 - val_accuracy: 0.9369\n",
      "Epoch 35/50\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 3.5073e-04 - accuracy: 1.0000 - val_loss: 0.3515 - val_accuracy: 0.9364\n",
      "Epoch 36/50\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 3.2820e-04 - accuracy: 1.0000 - val_loss: 0.3528 - val_accuracy: 0.9369\n",
      "Epoch 37/50\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 2.9907e-04 - accuracy: 1.0000 - val_loss: 0.3575 - val_accuracy: 0.9374\n",
      "Epoch 38/50\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 2.6857e-04 - accuracy: 1.0000 - val_loss: 0.3784 - val_accuracy: 0.9359\n",
      "Epoch 39/50\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 2.5494e-04 - accuracy: 1.0000 - val_loss: 0.3733 - val_accuracy: 0.9350\n",
      "Epoch 40/50\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 2.1750e-04 - accuracy: 1.0000 - val_loss: 0.3711 - val_accuracy: 0.9369\n",
      "Epoch 41/50\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 2.0965e-04 - accuracy: 1.0000 - val_loss: 0.3714 - val_accuracy: 0.9359\n",
      "Epoch 42/50\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.9781e-04 - accuracy: 1.0000 - val_loss: 0.3734 - val_accuracy: 0.9359\n",
      "Epoch 43/50\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 1.6588e-04 - accuracy: 1.0000 - val_loss: 0.3820 - val_accuracy: 0.9364\n",
      "Epoch 44/50\n",
      "98/98 [==============================] - 1s 11ms/step - loss: 1.4730e-04 - accuracy: 1.0000 - val_loss: 0.3887 - val_accuracy: 0.9355\n",
      "Epoch 45/50\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.3409e-04 - accuracy: 1.0000 - val_loss: 0.3942 - val_accuracy: 0.9350\n",
      "Epoch 46/50\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.2086e-04 - accuracy: 1.0000 - val_loss: 0.4005 - val_accuracy: 0.9350\n",
      "Epoch 47/50\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 1.1142e-04 - accuracy: 1.0000 - val_loss: 0.4030 - val_accuracy: 0.9355\n",
      "Epoch 48/50\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 1.0045e-04 - accuracy: 1.0000 - val_loss: 0.4086 - val_accuracy: 0.9350\n",
      "Epoch 49/50\n",
      "98/98 [==============================] - 1s 12ms/step - loss: 9.6063e-05 - accuracy: 1.0000 - val_loss: 0.3988 - val_accuracy: 0.9364\n",
      "Epoch 50/50\n",
      "98/98 [==============================] - 1s 12ms/step - loss: 8.9540e-05 - accuracy: 1.0000 - val_loss: 0.4047 - val_accuracy: 0.9359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b4fbaf0790>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init()\n",
    "model.fit(X_train, y_train_hot, epochs=config.epochs, validation_data=(X_test, y_test_hot), callbacks=[WandbCallback(data_type=\"image\", labels=labels)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e783f838-4410-47e1-8a52-22a47f821c92",
   "metadata": {},
   "source": [
    "# HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "396066d9-0d1f-4ddb-ac8c-0f3348894979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Conv2D(\n",
    "        filters=hp.Int('conv_1_filter', min_value = 32, max_value= 128, step=16),\n",
    "        kernel_size = hp.Choice('conv_1_kernel', values = [3,5]),\n",
    "        activation = 'relu',\n",
    "        input_shape=(config.buckets, config.max_len, channels)\n",
    "        ),\n",
    "        keras.layers.Conv2D(\n",
    "        filters=hp.Int('conv_2_filter', min_value = 32, max_value= 64, step=16),\n",
    "        kernel_size = hp.Choice('conv_2_kernel', values = [3,5]),\n",
    "        activation = 'relu',\n",
    "        input_shape=(config.buckets, config.max_len, channels),\n",
    "        ),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(\n",
    "        units=hp.Int('dense_1_units', min_value = 32, max_value=128, step=16),\n",
    "        activation='relu'\n",
    "        ),\n",
    "        keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer= tf.keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2,1e-3])),\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8f840fe1-1037-4ef8-b515-a6fcb38cbc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bc9c712a-f422-4031-8fa2-2bd6fb2d611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_search=RandomSearch(build_model, \n",
    "                         objective='val_accuracy',\n",
    "                         max_trials = 5,\n",
    "                         directory = 'output',\n",
    "                         project_name= \"Audio Transcribers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f6edd0d4-80af-46fb-bce5-e3d91e8ed0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 03s]\n",
      "val_accuracy: 0.8782051205635071\n",
      "\n",
      "Best val_accuracy So Far: 0.8782051205635071\n",
      "Total elapsed time: 00h 00m 14s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner_search.search(X_train, y_train_hot, epochs=1, validation_split=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962e8b40-60e4-4edd-9dbc-6d10bb5efa48",
   "metadata": {},
   "source": [
    "# Tuning With For Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7c128cbf-3cb5-4886-83a3-c1d0b0ae0903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(fil, kernel, lr):\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Conv2D(\n",
    "        filters= fil,\n",
    "        kernel_size =kernel,\n",
    "        activation = 'relu',\n",
    "        input_shape=(config.buckets, config.max_len, channels)\n",
    "        ),\n",
    "        keras.layers.Conv2D(\n",
    "        filters= fil,\n",
    "        kernel_size =kernel,\n",
    "        activation = 'relu',\n",
    "        input_shape=(config.buckets, config.max_len, channels)\n",
    "        ),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(\n",
    "        units=fil,\n",
    "        activation='relu'\n",
    "        ),\n",
    "        keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer= tf.keras.optimizers.Adam(lr),\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e292514f-df6d-47b3-9f7e-20d07c468eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 4.9669 - accuracy: 0.3252 - val_loss: 5.8332 - val_accuracy: 0.3285\n",
      "Epoch 2/50\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 4.7037 - accuracy: 0.3387 - val_loss: 4.7600 - val_accuracy: 0.3420\n",
      "Epoch 3/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 3.5473 - accuracy: 0.3287 - val_loss: 2.5307 - val_accuracy: 0.3420\n",
      "Epoch 4/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 4.7934 - accuracy: 0.3406 - val_loss: 3.3740 - val_accuracy: 0.3295\n",
      "Epoch 5/50\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 3.2218 - accuracy: 0.3255 - val_loss: 2.8124 - val_accuracy: 0.3295\n",
      "Epoch 6/50\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 3.2512 - accuracy: 0.3605 - val_loss: 5.0907 - val_accuracy: 0.3420\n",
      "Epoch 7/50\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 3.7672 - accuracy: 0.3332 - val_loss: 5.8342 - val_accuracy: 0.3285\n",
      "Epoch 8/50\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 4.8678 - accuracy: 0.3355 - val_loss: 3.6190 - val_accuracy: 0.3285\n",
      "Epoch 9/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 4.8201 - accuracy: 0.3442 - val_loss: 4.1584 - val_accuracy: 0.3295\n",
      "Epoch 10/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 3.4977 - accuracy: 0.3262 - val_loss: 7.0837 - val_accuracy: 0.3420\n",
      "Epoch 11/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 5.1226 - accuracy: 0.3364 - val_loss: 3.0209 - val_accuracy: 0.3285\n",
      "Epoch 12/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 3.8377 - accuracy: 0.3348 - val_loss: 3.7309 - val_accuracy: 0.3420\n",
      "Epoch 13/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 3.4152 - accuracy: 0.3326 - val_loss: 2.3574 - val_accuracy: 0.3420\n",
      "Epoch 14/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 3.2157 - accuracy: 0.3358 - val_loss: 3.0447 - val_accuracy: 0.3295\n",
      "Epoch 15/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 2.5963 - accuracy: 0.3461 - val_loss: 1.4300 - val_accuracy: 0.3285\n",
      "Epoch 16/50\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 3.4952 - accuracy: 0.3146 - val_loss: 4.5971 - val_accuracy: 0.3285\n",
      "Epoch 17/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 3.6006 - accuracy: 0.3294 - val_loss: 4.8110 - val_accuracy: 0.3420\n",
      "Epoch 18/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 4.3720 - accuracy: 0.3374 - val_loss: 6.9117 - val_accuracy: 0.3285\n",
      "Epoch 19/50\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 4.3866 - accuracy: 0.3403 - val_loss: 11.0567 - val_accuracy: 0.3285\n",
      "Epoch 20/50\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 6.4361 - accuracy: 0.3393 - val_loss: 1.3602 - val_accuracy: 0.3285\n",
      "Epoch 21/50\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 3.5549 - accuracy: 0.3403 - val_loss: 5.8003 - val_accuracy: 0.3420\n",
      "Epoch 22/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 4.7220 - accuracy: 0.3374 - val_loss: 4.2865 - val_accuracy: 0.3285\n",
      "Epoch 23/50\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 3.9112 - accuracy: 0.3368 - val_loss: 3.2036 - val_accuracy: 0.3295\n",
      "Epoch 24/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 4.3495 - accuracy: 0.3438 - val_loss: 3.3226 - val_accuracy: 0.3420\n",
      "Epoch 25/50\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 5.9437 - accuracy: 0.3262 - val_loss: 6.7214 - val_accuracy: 0.3295\n",
      "Epoch 26/50\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 3.8366 - accuracy: 0.3342 - val_loss: 3.0063 - val_accuracy: 0.3295\n",
      "Epoch 27/50\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 4.1332 - accuracy: 0.3470 - val_loss: 2.0607 - val_accuracy: 0.3295\n",
      "Epoch 28/50\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 2.5603 - accuracy: 0.3329 - val_loss: 1.8567 - val_accuracy: 0.3295\n",
      "Epoch 29/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 3.8084 - accuracy: 0.3168 - val_loss: 9.9741 - val_accuracy: 0.3285\n",
      "Epoch 30/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 5.4431 - accuracy: 0.3438 - val_loss: 13.5159 - val_accuracy: 0.3295\n",
      "Epoch 31/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 6.7725 - accuracy: 0.3233 - val_loss: 1.1530 - val_accuracy: 0.3295\n",
      "Epoch 32/50\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 4.4149 - accuracy: 0.3377 - val_loss: 2.0986 - val_accuracy: 0.3285\n",
      "Epoch 33/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 3.1468 - accuracy: 0.3348 - val_loss: 2.7016 - val_accuracy: 0.3420\n",
      "Epoch 34/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 3.4280 - accuracy: 0.3345 - val_loss: 1.7983 - val_accuracy: 0.3420\n",
      "Epoch 35/50\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 4.8589 - accuracy: 0.3252 - val_loss: 9.6398 - val_accuracy: 0.3285\n",
      "Epoch 36/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 5.4525 - accuracy: 0.3287 - val_loss: 2.5025 - val_accuracy: 0.3420\n",
      "Epoch 37/50\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 3.9125 - accuracy: 0.3303 - val_loss: 4.9410 - val_accuracy: 0.3285\n",
      "Epoch 38/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 5.5187 - accuracy: 0.3262 - val_loss: 2.1794 - val_accuracy: 0.3285\n",
      "Epoch 39/50\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 2.8239 - accuracy: 0.3438 - val_loss: 4.3508 - val_accuracy: 0.3295\n",
      "Epoch 40/50\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 4.2105 - accuracy: 0.3364 - val_loss: 1.7052 - val_accuracy: 0.3295\n",
      "Epoch 41/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 4.3279 - accuracy: 0.3290 - val_loss: 5.6885 - val_accuracy: 0.3285\n",
      "Epoch 42/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 5.1878 - accuracy: 0.3281 - val_loss: 13.7270 - val_accuracy: 0.3285\n",
      "Epoch 43/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 4.6816 - accuracy: 0.3364 - val_loss: 2.6509 - val_accuracy: 0.3420\n",
      "Epoch 44/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 3.3716 - accuracy: 0.3345 - val_loss: 4.9118 - val_accuracy: 0.3420\n",
      "Epoch 45/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 7.0153 - accuracy: 0.3139 - val_loss: 4.1101 - val_accuracy: 0.3420\n",
      "Epoch 46/50\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 3.9876 - accuracy: 0.3217 - val_loss: 5.4612 - val_accuracy: 0.3420\n",
      "Epoch 47/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 2.8258 - accuracy: 0.3323 - val_loss: 2.5205 - val_accuracy: 0.3295\n",
      "Epoch 48/50\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 2.5972 - accuracy: 0.3380 - val_loss: 2.9754 - val_accuracy: 0.3285\n",
      "Epoch 49/50\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 3.5632 - accuracy: 0.3390 - val_loss: 2.1207 - val_accuracy: 0.3285\n",
      "Epoch 50/50\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 3.6931 - accuracy: 0.3201 - val_loss: 2.4823 - val_accuracy: 0.3420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b4fece3610>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_model(1,3,32).fit(X_train, y_train_hot, epochs=config.epochs, validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "174b2652-824c-4398-a001-659ae2f81801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "98/98 [==============================] - 2s 13ms/step - loss: 466213.3438 - accuracy: 0.3310 - val_loss: 1.4041 - val_accuracy: 0.3285\n",
      "Epoch 2/50\n",
      "98/98 [==============================] - 1s 11ms/step - loss: 1.3011 - accuracy: 0.3255 - val_loss: 1.8366 - val_accuracy: 0.3285\n",
      "Epoch 3/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 1.2552 - accuracy: 0.3358 - val_loss: 1.2489 - val_accuracy: 0.3295\n",
      "Epoch 4/50\n",
      "98/98 [==============================] - 1s 11ms/step - loss: 1.2866 - accuracy: 0.3380 - val_loss: 1.1132 - val_accuracy: 0.3420\n",
      "Epoch 5/50\n",
      "98/98 [==============================] - 1s 11ms/step - loss: 1.2240 - accuracy: 0.3335 - val_loss: 1.1012 - val_accuracy: 0.3285\n",
      "Epoch 6/50\n",
      "98/98 [==============================] - 1s 11ms/step - loss: 1.3190 - accuracy: 0.3487 - val_loss: 1.3093 - val_accuracy: 0.3285\n",
      "Epoch 7/50\n",
      "98/98 [==============================] - 1s 12ms/step - loss: 1.3394 - accuracy: 0.3303 - val_loss: 1.1029 - val_accuracy: 0.3285\n",
      "Epoch 8/50\n",
      "98/98 [==============================] - 1s 12ms/step - loss: 1.2298 - accuracy: 0.3323 - val_loss: 1.2230 - val_accuracy: 0.3295\n",
      "Epoch 9/50\n",
      "98/98 [==============================] - 1s 13ms/step - loss: 1.3115 - accuracy: 0.3236 - val_loss: 1.1868 - val_accuracy: 0.3285\n",
      "Epoch 10/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 1.2308 - accuracy: 0.3480 - val_loss: 1.3975 - val_accuracy: 0.3285\n",
      "Epoch 11/50\n",
      " 7/98 [=>............................] - ETA: 0s - loss: 1.2689 - accuracy: 0.3839"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-edc524bd5d80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkernel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfil\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m             \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfil\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_hot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_hot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\tojer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\wandb\\integration\\keras\\keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tojer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tojer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1219\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1220\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1221\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1222\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tojer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    434\u001b[0m     \"\"\"\n\u001b[0;32m    435\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tojer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m       raise ValueError(\n",
      "\u001b[1;32mc:\\users\\tojer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tojer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m       \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tojer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tojer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m       \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1104\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1105\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tojer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    552\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 554\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tojer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tojer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tojer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    548\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tojer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \"\"\"\n\u001b[0;32m   1148\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tojer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1113\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1115\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1116\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1117\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for lr in range (1, 3):\n",
    "    for kernel in range (3,5):\n",
    "        for fil in range(32, 128,16):\n",
    "            build_model(fil,kernel,lr).fit(X_train, y_train_hot, epochs=config.epochs, validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75710f8-69d9-455e-9f71-7f35b108516d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
